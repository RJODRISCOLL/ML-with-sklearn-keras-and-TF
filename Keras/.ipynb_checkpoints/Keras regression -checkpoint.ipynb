{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup notebook\n",
    "\n",
    "In this notebook i build a simple a neural network to predict housing prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to C:\\Users\\ruair\\scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# dataset imort \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we scale the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # scaler \n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_valid = scaler.transform(X_valid) # validation set \n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build a seuqential NN with a single output neuron! We know that the dataset is pretty noisy so we \n",
    "# we need to avoid overfitting so we dont build a very deep network \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 4.0900 - val_loss: 3.4560\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 3.0450 - val_loss: 2.5711\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 2.3642 - val_loss: 2.0048\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 1.9094 - val_loss: 1.6338\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 1.5979 - val_loss: 1.3843\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 1.3792 - val_loss: 1.2120\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 1.2217 - val_loss: 1.0893\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 1.1061 - val_loss: 0.9995\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 1.0199 - val_loss: 0.9324\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.9544 - val_loss: 0.8818\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.9041 - val_loss: 0.8430\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.8655 - val_loss: 0.8129\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.8353 - val_loss: 0.7895\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.8114 - val_loss: 0.7709\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.7922 - val_loss: 0.7561\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.7766 - val_loss: 0.7440\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.7638 - val_loss: 0.7342\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.7532 - val_loss: 0.7259\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.7442 - val_loss: 0.7188\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.7364 - val_loss: 0.7127\n",
      "5160/5160 [==============================] - 0s 32us/sample - loss: 0.6987\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", \n",
    "              optimizer=keras.optimizers.SGD(lr=0.0001)) # learning rate of g desc\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test) # we evaluate the model \n",
    "X_new = X_test[:3] # look at 3 instances \n",
    "y_pred = model.predict(X_new) # make predictions on these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets plot the loss over tiem\n",
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.090036</td>\n",
       "      <td>3.456013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.045026</td>\n",
       "      <td>2.571059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.364225</td>\n",
       "      <td>2.004838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.909414</td>\n",
       "      <td>1.633752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.597857</td>\n",
       "      <td>1.384306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.379172</td>\n",
       "      <td>1.211955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.221748</td>\n",
       "      <td>1.089280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.106104</td>\n",
       "      <td>0.999492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.019867</td>\n",
       "      <td>0.932447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.954365</td>\n",
       "      <td>0.881789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.904122</td>\n",
       "      <td>0.842965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.865471</td>\n",
       "      <td>0.812860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.835274</td>\n",
       "      <td>0.789470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.811363</td>\n",
       "      <td>0.770938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.792187</td>\n",
       "      <td>0.756061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.776627</td>\n",
       "      <td>0.744017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.763828</td>\n",
       "      <td>0.734163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.753209</td>\n",
       "      <td>0.725890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.744219</td>\n",
       "      <td>0.718834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.736423</td>\n",
       "      <td>0.712680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  val_loss\n",
       "0   4.090036  3.456013\n",
       "1   3.045026  2.571059\n",
       "2   2.364225  2.004838\n",
       "3   1.909414  1.633752\n",
       "4   1.597857  1.384306\n",
       "5   1.379172  1.211955\n",
       "6   1.221748  1.089280\n",
       "7   1.106104  0.999492\n",
       "8   1.019867  0.932447\n",
       "9   0.954365  0.881789\n",
       "10  0.904122  0.842965\n",
       "11  0.865471  0.812860\n",
       "12  0.835274  0.789470\n",
       "13  0.811363  0.770938\n",
       "14  0.792187  0.756061\n",
       "15  0.776627  0.744017\n",
       "16  0.763828  0.734163\n",
       "17  0.753209  0.725890\n",
       "18  0.744219  0.718834\n",
       "19  0.736423  0.712680"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5161452],\n",
       "       [1.6750615],\n",
       "       [2.2877629]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API\n",
    "\n",
    "Here we implement a more complex topology. This innovative NN allows for the modelling of relatively simple patterns, as well as very deep, complex rules. In contrast, a regular MLP will require all data to pass through the 'deep' path, which can results in simple patterns becoming overly complex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first implement an input object - this defines shape of the layer \n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation ='relu')(input_) # input is passed to the first hidden layer\n",
    "hidden2 = keras.layers.Dense(30, activation ='relu')(hidden1) # hidden1 is passed to the second hidden layer\n",
    "concat = keras.layers.Concatenate()([input_, hidden2]) # input and hidden 2 are concatenated in this lyer \n",
    "output = keras.layers.Dense(1)(concat) # single layer output because this is an output \n",
    "#model = keras.Model(inputs = [input_], output = [output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train the model above but we need to make some tweaks if the algo is to take specific subsets of features to hsallow/deep componentns. If we want to or need to, we can send specific input to both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here input a is fed through a shoter part. \n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 4.5780 - val_loss: 3.8817\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 3.4099 - val_loss: 2.9111\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 2.5439 - val_loss: 2.2168\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 1.9367 - val_loss: 1.7562\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 1.5321 - val_loss: 1.4634\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 1.2737 - val_loss: 1.2779\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 1.1117 - val_loss: 1.1596\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 1.0099 - val_loss: 1.0796\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.9440 - val_loss: 1.0218\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.8996 - val_loss: 0.9776\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 0.8677 - val_loss: 0.9423\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 0.8437 - val_loss: 0.9124\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 0.8248 - val_loss: 0.8869\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 83us/sample - loss: 0.8091 - val_loss: 0.8642\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 74us/sample - loss: 0.7958 - val_loss: 0.8439\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 0.7843 - val_loss: 0.8262\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 81us/sample - loss: 0.7741 - val_loss: 0.8108\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 91us/sample - loss: 0.7652 - val_loss: 0.7970\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 87us/sample - loss: 0.7571 - val_loss: 0.7848\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 79us/sample - loss: 0.7498 - val_loss: 0.7739\n",
      "5160/5160 [==============================] - 0s 36us/sample - loss: 0.6929\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.0001))\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:] # in this ecample we split the cols, note some overlap\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note below we must split the input matrices into train a and train , to account for the different inputs. WHy would we need this? \n",
    "\n",
    "- the task may require it. i.e. some tasks may require classification AND regression \n",
    "- If you genereally have more than one task per dataset. THis is often a superior approach to > network.\n",
    "- Regularisation techniques. If we add an auxillary component we may ensure that the network learn ssomething on its own with out relying oon the rest of the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 136us/sample - loss: 1.8073 - main_output_loss: 1.6018 - aux_output_loss: 3.6518 - val_loss: 1.1499 - val_main_output_loss: 0.9454 - val_aux_output_loss: 2.9893\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.8908 - main_output_loss: 0.7165 - aux_output_loss: 2.4611 - val_loss: 0.8345 - val_main_output_loss: 0.6833 - val_aux_output_loss: 2.1948\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 0.7614 - main_output_loss: 0.6382 - aux_output_loss: 1.8685 - val_loss: 0.7401 - val_main_output_loss: 0.6205 - val_aux_output_loss: 1.8166\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.7015 - main_output_loss: 0.6020 - aux_output_loss: 1.5964 - val_loss: 0.6937 - val_main_output_loss: 0.5903 - val_aux_output_loss: 1.6239\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.6695 - main_output_loss: 0.5816 - aux_output_loss: 1.4594 - val_loss: 0.6646 - val_main_output_loss: 0.5726 - val_aux_output_loss: 1.4935\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 98us/sample - loss: 0.6428 - main_output_loss: 0.5617 - aux_output_loss: 1.3726 - val_loss: 0.6396 - val_main_output_loss: 0.5538 - val_aux_output_loss: 1.4125\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.6240 - main_output_loss: 0.5477 - aux_output_loss: 1.3103 - val_loss: 0.6194 - val_main_output_loss: 0.5394 - val_aux_output_loss: 1.3397\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 0.6061 - main_output_loss: 0.5329 - aux_output_loss: 1.2624 - val_loss: 0.6040 - val_main_output_loss: 0.5288 - val_aux_output_loss: 1.2809\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 99us/sample - loss: 0.5916 - main_output_loss: 0.5214 - aux_output_loss: 1.2216 - val_loss: 0.5927 - val_main_output_loss: 0.5217 - val_aux_output_loss: 1.2317\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 102us/sample - loss: 0.5789 - main_output_loss: 0.5116 - aux_output_loss: 1.1847 - val_loss: 0.5788 - val_main_output_loss: 0.5112 - val_aux_output_loss: 1.1883\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 0.5669 - main_output_loss: 0.5019 - aux_output_loss: 1.1526 - val_loss: 0.5680 - val_main_output_loss: 0.5034 - val_aux_output_loss: 1.1505\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 103us/sample - loss: 0.5585 - main_output_loss: 0.4957 - aux_output_loss: 1.1229 - val_loss: 0.5592 - val_main_output_loss: 0.4974 - val_aux_output_loss: 1.1163\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 98us/sample - loss: 0.5490 - main_output_loss: 0.4883 - aux_output_loss: 1.0964 - val_loss: 0.5518 - val_main_output_loss: 0.4926 - val_aux_output_loss: 1.0853\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 99us/sample - loss: 0.5420 - main_output_loss: 0.4832 - aux_output_loss: 1.0698 - val_loss: 0.5452 - val_main_output_loss: 0.4880 - val_aux_output_loss: 1.0600\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 0.5356 - main_output_loss: 0.4788 - aux_output_loss: 1.0461 - val_loss: 0.5382 - val_main_output_loss: 0.4830 - val_aux_output_loss: 1.0359\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 98us/sample - loss: 0.5291 - main_output_loss: 0.4740 - aux_output_loss: 1.0241 - val_loss: 0.5339 - val_main_output_loss: 0.4806 - val_aux_output_loss: 1.0143\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.5240 - main_output_loss: 0.4706 - aux_output_loss: 1.0036 - val_loss: 0.5272 - val_main_output_loss: 0.4754 - val_aux_output_loss: 0.9934\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.5189 - main_output_loss: 0.4670 - aux_output_loss: 0.9848 - val_loss: 0.5228 - val_main_output_loss: 0.4726 - val_aux_output_loss: 0.9753\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 0.5134 - main_output_loss: 0.4630 - aux_output_loss: 0.9661 - val_loss: 0.5178 - val_main_output_loss: 0.4689 - val_aux_output_loss: 0.9588\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.5092 - main_output_loss: 0.4601 - aux_output_loss: 0.9500 - val_loss: 0.5129 - val_main_output_loss: 0.4652 - val_aux_output_loss: 0.9429\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 53us/sample - loss: 0.4900 - main_output_loss: 0.4431 - aux_output_loss: 0.9270\n"
     ]
    }
   ],
   "source": [
    "#main labels and the auxillatry output need to predict the same thing\n",
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss:  0.4900002552557361\n",
      "Main loss:  0.44314834\n",
      "Aux loss:  0.9269979\n"
     ]
    }
   ],
   "source": [
    "print ('Total loss: ' ,total_loss)\n",
    "print ('Main loss: ', main_loss)\n",
    "print ('Aux loss: ', aux_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9546523],\n",
       "       [1.8934373],\n",
       "       [2.414296 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
