{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will work in this project with the famours MNIST data. THis is a handwritten database of digits and is so widely studied that many refer to it as the 'hello world' of machine learning. \n",
    "\n",
    "Lets get the project set up: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (70000, 784)\n",
      "y shape = (70000,)\n"
     ]
    }
   ],
   "source": [
    "# check the data in mnist\n",
    "X, y = mnist['data'], mnist['target']\n",
    "print('X shape =', X.shape)\n",
    "print('y shape =', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that there are 70,000 images and each of the images has 784 pixels. The features in mnist represent the intensity of the pixel, where they vary fro 0 which is white to 255 which is black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[575]\n",
    "some_digit_img = some_digit.reshape(28,28)\n",
    "plt.imshow(some_digit_img, cmap = 'binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that this is an 8\n",
    "y[575]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver to a nnumber as the algorithms do not take strings\n",
    "import numpy as np\n",
    "y=y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a test and train set, note that mnist is already random order \n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's start with a more simple approach (a binary classifyer that simply predicts a single digit). we train the stochastic gradient descent classifiyer below. SGD is a highly efficient method as it learns from single instances independantly. It relies on randomness and therefore we must set the seed number. \n",
    "\n",
    "Notes on sgd: \n",
    "SGD Classifier implements regularised linear models with Stochastic Gradient Descent.Note that this algorithm is just a linear classifier optimised by the SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_1 = (y_train == 1)\n",
    "y_test_1 = (y_test == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=18, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "sgd_clf = SGDClassifier(random_state = 18)\n",
    "sgd_clf.fit(X_train, y_train_1)# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets evaluate the performance with cross validation. We need a bit more control here and therefore we write a function tat extends beyond the cv score offered by sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruair\\cond\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98765\n",
      "0.99045\n",
      "0.98985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits = 3, random_state = 42)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_1):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_1[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_1[test_index]\n",
    "    \n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred==y_test_fold)\n",
    "    print(n_correct/len(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98765, 0.99045, 0.98985])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the models \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_1, cv = 3, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_1, cv = 3) # returns predictions made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check from aconfusion matrix rather than simply correct measures first row is the negative class and the second is pos\n",
    "from sklearn.metrics import confusion_matrix \n",
    "confusion_matrix(y_train_1, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can evaluate the classifyers with precision and recall. Important to note that these metrics are often traded off against each other. That is; usually as the precision increases we will see a decrease in recall and this is called the precision recall tradeoff. Note that SGD can be optimised relative to your personal goals \n",
    "\n",
    "Precision = tp / tp + fp \n",
    "\n",
    "\n",
    "Recall = tp / tp + fn\n",
    "\n",
    "\n",
    "f1 = 2 * precision x recall / precision + recall \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision_score(y_train_1, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_1, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_train_1, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how can we decide on the threshold ofor the classifyer? \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_1, cv = 3, method = 'decision_function')\n",
    "precisions,recalls, thresholds = precision_recall_curve(y_train_1, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train_1, y_scores)\n",
    "\n",
    "def plt_ROC(fpr, tpr, label = None):\n",
    "    plt.plot(fpr, tpr, linewidth = 2, label = label)\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.legend()\n",
    "    \n",
    "plt_ROC(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_dt(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], 'b--', label = 'Precision')\n",
    "    plt.plot(thresholds, recalls[:-1], 'g-', label = 'Recall')\n",
    "    plt.legend()\n",
    "\n",
    "plt_dt(precisions, recalls, thresholds)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have a defined precision we need we can extract the threshold value i.e. 95% \n",
    "thresholds[np.argmax(precisions >=0.95)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve \n",
    "\n",
    "is a tool we can used in binary classifications. It plots the true positive vs false positive (1-TPR). We can evalueate the differences between classifyers with the roc AUC score, which lies between 1 (perfect) and 0.5 (random guesses)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score \n",
    "roc_auc_score(y_train_1, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets compare to a random forest nb that predict proba returns a probabilistic estimate of the accuracy per prediction\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "forest_clf = RandomForestClassifier(random_state = 18)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_1, cv = 3, method = 'predict_proba')\n",
    "\n",
    "y_scores_forest = y_probas_forest[:, 1]\n",
    "fpr_forest, tpr_forest, threshold_forest = roc_curve(y_train_1, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, 'b:', label='SGD')\n",
    "plt_ROC(fpr_forest, tpr_forest, 'RF')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SGD AUC',roc_auc_score(y_train_1, y_scores))\n",
    "print('RF AUC',roc_auc_score(y_train_1, y_scores_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # try svm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC() # support vector machine classfiyer \n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovr_clf = OneVsRestClassifier(SVC()) \n",
    "ovr_clf.fit(X_train, y_train)\n",
    "digit_scores = svm_clf.decision_function([some_digit]) \n",
    "digit_scores # score per digit out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardSCaler \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring = 'accuracy') # in this example we can impore accuracy by scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error work \n",
    "\n",
    "we can use the method below to understand where the common errors are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first create a c mat\n",
    "y_train_predictions = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_m = confusion_matrix(y_train, y_train_predictions)\n",
    "conf_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(conf_m)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we now look at where the common errors are \n",
    "row_sums = conf_m.sum(axis=1, keepdims=True)\n",
    "norm_fonf_m = conf_m/row_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use multiclass where the output is more than 1\n",
    "from sklearn.neighbours import KNeighborsClassifier\n",
    "\n",
    "y_train_large = (y_train>=7)\n",
    "y_train_odd = (y_train % 2 ==1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd] # concat these outputs \n",
    "knn_clf = KNeighborsClassifier(\n",
    "knn_clf.fit(X_train, y_multilabel) # now we get an output if large AND odd \n",
    "knn_clf.fit([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilevel, cv = 3)\n",
    "f1_score(y_multilabel, y_train_knn_pred, average = 'macro') # compute f1 across all levels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multioutput classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to add noise to the mnist data \n",
    "noise = np.random.randint(0,100, len(X_train), 784)\n",
    "X_train_mod = X_train + noise\n",
    "noise = np.random.randint(0,100, len(X_test), 784)\n",
    "X_test_mod = X_test + noise\n",
    "\n",
    "y_train_mod = X_train \n",
    "y_test_mod = X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 452\n",
    "plt.subplot(121); plot_digit(X_test_mod[idx])\n",
    "plt.subplot(122); plot_digit(y_test_mod[idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.fit(X_train_mod, y_train_mod)\n",
    "clean_digit = knn_clf.predict([X_test_mod[some_index]])\n",
    "plot_digit(clean_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
